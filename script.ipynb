{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'train.csv'\n",
    "\n",
    "data = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Exploratory Data Analysis\n",
    "\n",
    "## 1.1 Preliminary observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = data.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(exclude=['object']).describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=['object']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Exploring numerical columns\n",
    "\n",
    "### 1.2.1 Skew of target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.SalePrice\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(target)\n",
    "plt.title('Distribution of SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log(target))\n",
    "plt.title('Distribution of log-transformed SalePrice')\n",
    "plt.xlabel('log(SalePrice)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SalePrice has a skew of ' + str(target.skew().round(decimals=2)) + ' while the log-transformed SalePrice improves the skew to ' + str(np.log(target).skew().round(decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Distribution of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrs = data.select_dtypes(exclude=['object']).drop('SalePrice', axis=1).copy()\n",
    "\n",
    "fig = plt.figure(figsize=(12,18))\n",
    "for i in range(len(num_attrs.columns)):\n",
    "    fig.add_subplot(9,4,i+1)\n",
    "    sns.distplot(num_attrs.iloc[:,i].dropna())\n",
    "    plt.xlabel(num_attrs.columns[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewed dists could be potentially be log-transformed:\n",
    "+ LotFrontage\n",
    "+ LotArea\n",
    "+ 1stFlrSF\n",
    "+ GrLivArea\n",
    "+ OpenPorchSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Finding outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,18))\n",
    "\n",
    "for i in range(len(num_attrs.columns)):\n",
    "    fig.add_subplot(9,4, i+1)\n",
    "    sns.boxplot(y=num_attrs.iloc[:, i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(len(num_attrs.columns)):\n",
    "    fig.add_subplot(9,4,i+1)\n",
    "    sns.scatterplot(num_attrs.iloc[:, i], target)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14,12))\n",
    "plt.title('Correlation of numerical attributes', size=16)\n",
    "sns.heatmap(correlation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation['SalePrice'].sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_to_price = correlation['SalePrice']\n",
    "n_cols, n_rows = 5, 8\n",
    "fix, ax_arr = plt.subplots(n_rows, n_cols, figsize=(16,20), sharey=True)\n",
    "plt.subplots_adjust(bottom=-0.8)\n",
    "for j in range(n_rows):\n",
    "    for i in range(n_cols):\n",
    "        plt.sca(ax_arr[j, i])\n",
    "        index = i + j*n_cols\n",
    "        if index < len(num_cols):\n",
    "            plt.scatter(data[num_cols[index]], data.SalePrice)\n",
    "            plt.xlabel(num_cols[index])\n",
    "            plt.title('Corr to SalePrice = ' + str(np.around(corr_to_price[index], decimals=3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing/Null values in numerical cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrs.isna().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Exploring categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = data['KitchenQual']\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "sns.boxplot(var, data.SalePrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,8))\n",
    "sns.boxplot(data['Neighborhood'], data['SalePrice'])\n",
    "plt.xticks(rotation=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of categories within Neighborhood attribute\n",
    "fig = plt.figure(figsize=(12.5,4))\n",
    "sns.countplot(x='Neighborhood', data=data)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing/null values in categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cat_cols].isna().sum().sort_values(ascending=False).head(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning & Preprocessing\n",
    "\n",
    "## 2.1 Dealing w/ missing/null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of dataset\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Numerical columns\n",
    "data_copy['MasVnrArea'] = data_copy['MasVnrArea'].fillna(0)\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols_fill_none = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',\n",
    "                     'GarageCond', 'GarageQual', 'GarageFinish', 'GarageType',\n",
    "                     'BsmtFinType2', 'BsmtExposure', 'BsmtFinType1', 'BsmtQual', 'BsmtCond',\n",
    "                     'MasVnrType']\n",
    "\n",
    "for cat in cat_cols_fill_none:\n",
    "    data_copy[cat] = data_copy[cat].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outstanding missing/null values\n",
    "# Use imputer for these\n",
    "data_copy.isna().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adressing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers based on observations on scatter plots against SalePrice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Transforming data to reduce skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['SalePrice'] = np.log(data_copy['SalePrice'])\n",
    "data_copy = data_copy.rename(columns={'SalePrice': 'SalePrice_log'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Feature Selection & Engineering\n",
    "\n",
    "Considering highly-correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_corr = data_copy.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(transformed_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highly-correlated attrubtes include\n",
    "\n",
    "- GarageCars and GarageArea\n",
    "- YearBuilt and GarageYrBlt\n",
    "- GrLiveArea and TotRmsAbvGrd\n",
    "- TotalBsmtSF and 1stFlrSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature selection and encoding of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove attrs that were identified for excluding when viewing scatter plots & corr values\n",
    "attrs_drop = ['SalePrice_log', 'MiscVal', 'MSSubClass', 'MoSold', 'YrSold', \n",
    "                   'GarageArea', 'GarageYrBlt', 'TotRmsAbvGrd']\n",
    "\n",
    "X = data_copy.drop(attrs_drop, axis=1)\n",
    "\n",
    "y = data_copy.SalePrice_log\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Normalization\n",
    "normalizer = StandardScaler()\n",
    "train_X = normalizer.fit_transform(train_X)\n",
    "val_X = normalizer.transform(val_X)\n",
    "\n",
    "# Final imputation of missing data\n",
    "my_imputer = SimpleImputer()\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "val_X = my_imputer.transform(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverser trafo from log(SalePrice) to SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_y(transformed_y):\n",
    "    return np.exp(transformed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series to collate mae for each algo\n",
    "mea_compare = pd.Series()\n",
    "mea_compare.index.name = 'Algorithm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor(random_state=1)\n",
    "dt_model.fit(train_X, train_y)\n",
    "dt_pred = dt_model.predict(val_X)\n",
    "dt_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(dt_pred))\n",
    "print(f'Validation MAE for DecisionTree: {dt_val_mae:.2f}')\n",
    "mea_compare['DecisionTree'] = dt_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/ max leaf nodes of 90\n",
    "dt_model = DecisionTreeRegressor(random_state=1, max_leaf_nodes=90)\n",
    "dt_model.fit(train_X, train_y)\n",
    "dt_pred = dt_model.predict(val_X)\n",
    "dt_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(dt_pred))\n",
    "print(f'Validation MAE for DecisionTree wit max leaf nodes of 90: {dt_val_mae:.2f}')\n",
    "mea_compare['DecisionTree_with_max_leaf_nodes'] = dt_val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(random_state=5)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_pred = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(rf_pred))\n",
    "print(f'Validation MAE for Random Forest Model: {rf_val_mae:.2f}')\n",
    "mea_compare['RandomForest'] = rf_val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "xgb_model.fit(train_X, train_y, early_stopping_rounds=5, eval_set=[(val_X, val_y)], verbose=True)\n",
    "xgb_pred = xgb_model.predict(val_X)\n",
    "xgb_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(xgb_pred))\n",
    "print(f'Validation MAE for XGBoost Model: {xgb_val_mae:.2f}')\n",
    "mea_compare['XGBoost'] = xgb_val_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_model = LinearRegression()\n",
    "# linear_model.fit(train_X, train_y)\n",
    "# linear_pred = linear_model.predict(val_X)\n",
    "# linear_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(linear_pred))\n",
    "# print(f'Validation MAE for Linear Model: {linear_val_mae:.2f}') # dtype('float64') problem\n",
    "# mea_compare['LinearRegression'] = linear_val_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.0005, random_state=5)\n",
    "lasso_model.fit(train_X, train_y)\n",
    "lasso_pred = lasso_model.predict(val_X)\n",
    "lasso_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(lasso_pred))\n",
    "print(f'Validation MAE for Lasso Model: {lasso_val_mae:.2f}')\n",
    "mea_compare['Lasso'] = lasso_val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=0.0002, random_state=5)\n",
    "ridge_model.fit(train_X, train_y)\n",
    "ridge_pred = ridge_model.predict(val_X)\n",
    "ridge_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(ridge_pred))\n",
    "print(f'Validation MAE for Ridge Model: {ridge_val_mae:.2f}')\n",
    "mea_compare['Ridge'] = ridge_val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_model = ElasticNet(alpha=0.02, random_state=5, l1_ratio=0.7)\n",
    "elastic_net_model.fit(train_X, train_y)\n",
    "elastic_net_pred = elastic_net_model.predict(val_X)\n",
    "elastic_net_val_mae = mean_absolute_error(inverse_y(val_y), inverse_y(elastic_net_pred))\n",
    "print(f'Validation MAE for ElasticNet Model: {elastic_net_val_mae:.2f}')\n",
    "mea_compare['ElasticNet'] = elastic_net_val_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "imputed_X = imputer.fit_transform(X)\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lasso_model, imputed_X, y, scoring='neg_mean_squared_error', cv=n_folds)\n",
    "lasso_mae_scores = np.sqrt(-scores)\n",
    "\n",
    "print('For Lasso model: ')\n",
    "print(lasso_mae_scores.round(decimals=2))\n",
    "print(f'Mean RMSE = {lasso_mae_scores.mean().round(decimals=3)}')\n",
    "print(f'Error std deviation = {lasso_mae_scores.std().round(decimals=3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algorithm Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Tuning Lasso\n",
    "param_grid = [{'alpha': [0.0007, 0.0005, 0.005]}]\n",
    "top_reg = Lasso()\n",
    "\n",
    "grid_search = GridSearchCV(top_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(imputed_X, y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file for predictions\n",
    "test_data_path = 'test.csv'\n",
    "\n",
    "# read test data\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data.copy()\n",
    "\n",
    "test_X['MasVnrArea'] = test_X['MasVnrArea'].fillna(0)\n",
    "\n",
    "for cat in cat_cols_fill_none:\n",
    "    test_X[cat] = test_X[cat].fillna('None')\n",
    "\n",
    "if 'SalePrice_log' in attrs_drop:\n",
    "    attrs_drop.remove('SalePrice_log')\n",
    "\n",
    "test_X = test_X.drop(attrs_drop, axis=1)\n",
    "\n",
    "test_X = pd.get_dummies(test_X)\n",
    "\n",
    "final_train, final_test = X.align(test_X, join='left', axis=1)\n",
    "\n",
    "final_test_imputed = my_imputer.transform(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final model\n",
    "\n",
    "final_model = Lasso(alpha=0.0005, random_state=5)\n",
    "final_train_imputed = my_imputer.fit_transform(final_train)\n",
    "\n",
    "final_model.fit(final_train_imputed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for submission\n",
    "\n",
    "test_preds = final_model.predict(final_test_imputed)\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id, 'SalePrice': inverse_y(test_preds)})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3a780432a6692f055fc893302473716a2bcf1d66447da6d2b1bd0203ca95197"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
